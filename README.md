# Subscription Retention (Customer Churn) Prediction

## Problem Statement

Subscription-based businesses often lose revenue due to customer churn.
The goal of this project is to predict whether a customer is likely to churn using historical customer data, enabling businesses to take proactive retention actions.

ğŸ¯ Business Use Case

Identify customers at high risk of churn

Support targeted retention campaigns

Improve customer lifetime value (CLV)

Assist business and marketing teams in decision-making

ğŸ§  Project Overview

This project implements a supervised machine learning classification pipeline to predict customer churn.
Multiple models were trained and evaluated, and the final model was selected based on generalization performance rather than accuracy alone.

The project also includes a Python-based application for real-time churn prediction.

ğŸ—‚ Dataset Information

Source: Kaggle

Type: Subscription-based customer dataset

Target Variable: Churn

Class Distribution: Imbalanced (churned customers are the minority class)

ğŸ“Œ Raw dataset files are intentionally excluded from the repository to follow best practices.

âš™ï¸ Machine Learning Workflow

Data cleaning and preprocessing

Handling categorical variables (encoding)

Feature scaling

Trainâ€“test split

Training multiple classification models

Model evaluation using classification metrics

Overfitting analysis (train vs test performance)

Hyperparameter tuning of the final model

ğŸ¤– Models Trained & Evaluated

The following models were trained and compared:

K-Nearest Neighbors (KNN)

Decision Tree

Logistic Regression

Support Vector Classifier (SVC)

Random Forest

AdaBoost

Gaussian Naive Bayes

ğŸ” Overfitting Analysis

KNN, Decision Tree, SVC, Random Forest, AdaBoost

Very high training accuracy

Significantly lower test performance

Identified as overfitting models

Logistic Regression & Gaussian Naive Bayes

Comparable train and test performance

Better generalization on unseen data

ğŸ† Final Model Selection

After comparing all models using precision, recall, F1-score, and confusion matrices,
Logistic Regression was selected as the final model because:

It showed good generalization

Balanced biasâ€“variance tradeoff

Better interpretability

More reliable performance on the minority (churn) class

Hyperparameter tuning was applied to further optimize the Logistic Regression model, and the final model was saved using pickle.

ğŸ“ˆ Model Evaluation (Final Model â€“ Logistic Regression)
Test Set Performance

Accuracy: ~0.67

Recall (Churn class): ~0.61

F1-Score (Churn class): ~0.27

ğŸ“Œ Recall was prioritized over accuracy, as identifying churned customers is more important than predicting non-churn.

ğŸ–¥ Application Interface

The project includes a Python application that allows users to:

Manually input customer features

Receive real-time churn predictions

ğŸš€ Planned Enhancement

Customer IDâ€“based prediction, where input features are automatically retrieved for existing customers.

ğŸ›  Tech Stack

Python

NumPy

Pandas

Scikit-learn

Matplotlib

Seaborn

â–¶ï¸ How to Run the Project
1ï¸âƒ£ Clone the repository
git clone https://github.com/prasin-k-m/Subscription-Retention-Prediction.git
cd Subscription-Retention-Prediction

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the application
python app_manual_input.py

4ï¸âƒ£ Explore the model development notebook
jupyter notebook model.ipynb

ğŸ“ Project Structure
Subscription-Retention-Prediction/
â”‚
â”œâ”€â”€ app_manual_input.py
â”œâ”€â”€ model.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore

ğŸ“Œ Notes on Model Artifacts

Trained model files, encoders, and scalers are excluded from version control.

This follows ML engineering best practices, as model artifacts are reproducible and environment-dependent.

ğŸ‘¤ Author

Prasin K M
Data Science | Machine Learning Projects
